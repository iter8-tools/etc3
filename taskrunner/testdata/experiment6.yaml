apiVersion: iter8.tools/v2alpha2
kind: Experiment
metadata:
  creationTimestamp: "2020-12-27T21:55:48Z"
  generation: 2
  name: sklearn-iris-experiment-6
  namespace: default
  selfLink: /apis/iter8.tools/v2alpha2/namespaces/default/experiments/sklearn-iris-experiment-6
  uid: b99489b6-a1b4-420f-9615-165d6ff88293
spec: 
  criteria: 
    indicators: 
      - 95th-percentile-tail-latency
    objectives: 
      - 
        metric: mean-latency
        upperLimit: 1k
      - 
        metric: error-rate
        upperLimit: 10m
    requestCount: request-count
  duration: 
    intervalSeconds: 15
    iterationsPerLoop: 10
  versionInfo:
    baseline:
      name: default
      variables:
      - name: revision
        value: revision1
    candidates:
    - name: canary
      variables:
      - name: revision
        value: revision2
      weightObjRef:
        apiVersion: serving.kubeflow.org/v1alpha2
        fieldPath: .spec.canaryTrafficPercent
        kind: InferenceService
        name: sklearn-iris
        namespace: default
  metrics: 
    - 
      metricObj: 
        apiVersion: iter8.tools/v2alpha2
        kind: Metric
        metadata:
          creationTimestamp: "2020-12-27T21:53:23Z"
          generation: 1
          name: mean-latency
          namespace: iter8-system
          resourceVersion: "1923"
          selfLink: /apis/iter8.tools/v2alpha2/namespaces/iter8-system/metrics/mean-latency
          uid: e17018f8-613d-47c7-bb07-c32a03befe2c
        spec: 
          description: "Mean latency"
          params: 
          - name: query
            value: "(sum(increase(revision_app_request_latencies_sum{service_name=~'.*$name'}[$interval]))or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{service_name=~'.*$name'}[$interval])) or on() vector(0))"
          provider: prometheus
          jqExpression: ".data.result[0].value[1] | tonumber"
          sampleSize: request-count
          type: Gauge
          units: milliseconds
          urlTemplate: url
      name: mean-latency
    - 
      metricObj: 
        apiVersion: iter8.tools/v2alpha2
        kind: Metric
        metadata:
          creationTimestamp: "2020-12-27T21:53:23Z"
          generation: 1
          name: error-rate
          namespace: iter8-system
          resourceVersion: "1922"
          selfLink: /apis/iter8.tools/v2alpha2/namespaces/iter8-system/metrics/error-rate
          uid: f9dc0774-eddc-4e44-8c27-b459f14dd4f8
        spec: 
          description: "Fraction of requests with error responses"
          params: 
          - name: query
            value: "(sum(increase(revision_app_request_latencies_sum{service_name=~'.*$name'}[$interval]))or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{service_name=~'.*$name'}[$interval])) or on() vector(0))"
          provider: prometheus
          jqExpression: ".data.result[0].value[1] | tonumber"
          sampleSize: request-count
          type: Gauge
          urlTemplate: url
      name: error-rate
    - 
      metricObj: 
        apiVersion: iter8.tools/v2alpha2
        kind: Metric
        metadata:
          creationTimestamp: "2020-12-27T21:53:23Z"
          generation: 1
          name: request-count
          namespace: iter8-system
          resourceVersion: "1924"
          selfLink: /apis/iter8.tools/v2alpha2/namespaces/iter8-system/metrics/request-count
          uid: f67ca0d6-5653-4f52-a0d9-7394a56e595a
        spec: 
          description: "Number of requests"
          params: 
          - name: query
            value: "(sum(increase(revision_app_request_latencies_sum{service_name=~'.*$name'}[$interval]))or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{service_name=~'.*$name'}[$interval])) or on() vector(0))"
          provider: prometheus
          jqExpression: ".data.result[0].value[1] | tonumber"
          type: Counter
          urlTemplate: url
      name: request-count
    - 
      metricObj: 
        apiVersion: iter8.tools/v2alpha2
        kind: Metric
        metadata:
          creationTimestamp: "2020-12-27T21:53:23Z"
          generation: 1
          name: 95th-percentile-tail-latency
          namespace: iter8-system
          resourceVersion: "1920"
          selfLink: /apis/iter8.tools/v2alpha2/namespaces/iter8-system/metrics/95th-percentile-tail-latency
          uid: b8375e54-33d1-4185-9eac-087ebf7693c9
        spec: 
          description: "95th percentile tail latency"
          params: 
          - name: query
            value: "(sum(increase(revision_app_request_latencies_sum{service_name=~'.*$name'}[$interval]))or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{service_name=~'.*$name'}[$interval])) or on() vector(0))"
          provider: prometheus
          jqExpression: ".data.result[0].value[1] | tonumber"
          sampleSize: request-count
          type: Gauge
          units: milliseconds
          urlTemplate: url
      name: 95th-percentile-tail-latency
  strategy: 
    handlers: 
      failure: finish
      finish: finish
      rollback: finish
      start: start
    actions:
      start:
      - run: echo "hello-world"
      - run: helm version
      finish:
      - run: kustomize build .
    testingPattern: Canary
    deploymentPattern: Progressive
    weights: 
      maxCandidateWeight: 100
      maxCandidateWeightIncrement: 10
  target: default/sklearn-iris
status:
  versionRecommendedForPromotion: default
  completedIterations: 0
  conditions: 
    - 
      lastTransitionTime: "2020-12-27T21:55:49Z"
      message: "Start handler 'start' launched"
      reason: StartHandlerLaunched
      status: "False"
      type: Completed
    - 
      lastTransitionTime: "2020-12-27T21:55:48Z"
      status: "False"
      type: Failed
  initTime: "2020-12-27T21:55:48Z"
  lastUpdateTime: "2020-12-27T21:55:48Z"
  message: "StartHandlerLaunched: Start handler 'start' launched"