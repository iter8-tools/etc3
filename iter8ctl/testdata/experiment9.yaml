# winner not found
apiVersion: iter8.tools/v2beta1
kind: Experiment
metadata:
  name: test-experiment-9
  namespace: test-namespace
spec:
  criteria:
    objectives:
    - metric: mean-latency
      upperLimit: 1k
    - metric: error-rate
      upperLimit: 10m
  duration:
    minIntervalBetweenLoops: 15
    maxLoops: 10
  backends:
  - name: backend
    description: "backend description"
    versionInfo:
    - name: v1-name-1
      interval: v1-interval-1
    - name: v2-name-1
      interval: v2-interval-2
    method: POST
    provider: provider
    jqExpression: jqExpression
    headers:
      header: "{{.variable-1}}::{{.variable-2}}"
    url: https://provider.url
    metrics: 
    - name: mean-latency
      description: "Mean latency"
      params:
        query: "(sum(increase(revision_app_request_latencies_sum{service_name=~'.*$name'}[$interval]))or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{service_name=~'.*$name'}[$interval])) or on() vector(0))"
      type: Gauge
      units: milliseconds
    - name: error-rate
      description: "Fraction of requests with error responses"
      params:
        query: "(sum(increase(revision_app_request_latencies_count{response_code_class!='2xx',service_name=~'.*$name'}[$interval])) or on() vector(0)) / (sum(increase(revision_app_request_latencies_count{service_name=~'.*$name'}[$interval])) or on() vector(0))"
      type: Gauge
    - name: request-count
      description: "Number of requests"
      params:
        query: "sum(increase(revision_app_request_latencies_count{service_name=~'.*$name'}[$interval])) or on() vector(0)"
      type: Counter
    - name: 95th-percentile-tail-latency
      description: "95th percentile tail latency"
      params:
        query: "histogram_quantile(0.95, sum(rate(revision_app_request_latencies_bucket{service_name=~'.*$name'}[$interval])) by (le))"
      type: Gauge
      units: milliseconds
  versionInfo: ["default", "canary"]
status:
  analysis:
    metrics:
    - error-rate: ["0"]
      mean-latency: [228419047620n]
    - error-rate: ["0"]
      mean-latency: [228419047620n]
    objectives: [[true, true], [true, true]]
    weights: [15, 85]
    winner:
        winnerFound: false
  completedLoops: 10
  conditions:
  - lastTransitionTime: "2020-12-28T18:36:14Z"
    message: Experiment completed successfully
    reason: ExperimentCompleted
    status: "True"
    type: Completed
  - lastTransitionTime: "2020-12-28T18:33:34Z"
    status: "False"
    type: Failed
  currentWeightDistribution: [15, 85]
  lastUpdateTime: "2020-12-28T18:36:14Z"
  message: 'ExperimentCompleted: Experiment completed successfully'
  versionRecommendedForPromotion: canary
  startTime: "2020-12-28T18:33:42Z"
